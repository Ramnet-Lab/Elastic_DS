{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f37b81b-3dcc-4fe0-adb8-c681af944f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /opt/conda/lib/python3.12/site-packages (8.17.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /opt/conda/lib/python3.12/site-packages (from elasticsearch) (8.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /opt/conda/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!source elsds/bin/activate\n",
    "!pip install elasticsearch pandas numpy\n",
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38ea8a3-285d-4e54-bedc-7c623d966505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data exported to normalized_data.csv\n",
      "Mapping data exported to mapping_data.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# Load the DataFrame from actual_data.csv\n",
    "# --------------------------------------------\n",
    "df = pd.read_csv(\"actual_data.csv\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 1: Create a Normalized Version of the DataFrame\n",
    "# --------------------------------------------\n",
    "\n",
    "# Make a copy of the data.\n",
    "df_norm = df.copy()\n",
    "\n",
    "# Function to normalize numeric data (min-max scaling).\n",
    "def normalize_numeric(series):\n",
    "    # If the series is boolean, convert it to integer.\n",
    "    if pd.api.types.is_bool_dtype(series):\n",
    "        series = series.astype(int)\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    # Avoid division by zero\n",
    "    if max_val - min_val != 0:\n",
    "        return (series - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Create a dictionary to hold mapping information for each column.\n",
    "mapping_dict = {}\n",
    "\n",
    "# Iterate over each column and transform its values.\n",
    "for col in df_norm.columns:\n",
    "    # If column contains list values, convert them to strings.\n",
    "    if df_norm[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        df_norm[col] = df_norm[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "    \n",
    "    # Process datetime columns: convert to integer timestamps then normalize.\n",
    "    if pd.api.types.is_datetime64_any_dtype(df_norm[col]):\n",
    "        series_int = df_norm[col].astype('int64')\n",
    "        min_val = series_int.min()\n",
    "        max_val = series_int.max()\n",
    "        # Save mapping for reverse normalization.\n",
    "        mapping_dict[col] = {\"type\": \"datetime\", \"min\": int(min_val), \"max\": int(max_val)}\n",
    "        df_norm[col] = normalize_numeric(series_int)\n",
    "    \n",
    "    # Process numeric columns.\n",
    "    elif pd.api.types.is_numeric_dtype(df_norm[col]):\n",
    "        min_val = df_norm[col].min()\n",
    "        max_val = df_norm[col].max()\n",
    "        mapping_dict[col] = {\"type\": \"numeric\", \"min\": min_val, \"max\": max_val}\n",
    "        df_norm[col] = normalize_numeric(df_norm[col])\n",
    "    \n",
    "    # Process categorical/object columns.\n",
    "    else:\n",
    "        df_norm[col] = df_norm[col].astype(str)\n",
    "        codes, uniques = pd.factorize(df_norm[col])\n",
    "        mapping = {}\n",
    "        n = len(uniques)\n",
    "        for i, val in enumerate(uniques):\n",
    "            # Calculate normalized value for each unique category.\n",
    "            if n > 1:\n",
    "                norm_value = i / (n - 1)\n",
    "            else:\n",
    "                norm_value = 0.0\n",
    "            mapping[str(norm_value)] = val\n",
    "        mapping_dict[col] = {\"type\": \"categorical\", \"mapping\": mapping}\n",
    "        if n > 1:\n",
    "            df_norm[col] = codes / (n - 1)\n",
    "        else:\n",
    "            df_norm[col] = 0.0\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 2: Write the Normalized Data to CSV\n",
    "# --------------------------------------------\n",
    "normalized_csv = \"normalized_data.csv\"\n",
    "df_norm.to_csv(normalized_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"Normalized data exported to {normalized_csv}\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 3: Write the Mapping Data to a CSV\n",
    "# --------------------------------------------\n",
    "# For each column, record the mapping information needed for reverse normalization.\n",
    "mapping_data = []\n",
    "for col, info in mapping_dict.items():\n",
    "    # For numeric and datetime types, record min and max.\n",
    "    if info[\"type\"] in [\"numeric\", \"datetime\"]:\n",
    "        mapping_data.append({\n",
    "            \"column\": col,\n",
    "            \"type\": info[\"type\"],\n",
    "            \"min\": info[\"min\"],\n",
    "            \"max\": info[\"max\"]\n",
    "        })\n",
    "    # For categorical columns, store the mapping as a JSON string.\n",
    "    elif info[\"type\"] == \"categorical\":\n",
    "        mapping_data.append({\n",
    "            \"column\": col,\n",
    "            \"type\": info[\"type\"],\n",
    "            \"mapping\": json.dumps(info[\"mapping\"])\n",
    "        })\n",
    "\n",
    "mapping_df = pd.DataFrame(mapping_data)\n",
    "mapping_csv = \"mapping_data.csv\"\n",
    "mapping_df.to_csv(mapping_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"Mapping data exported to {mapping_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
