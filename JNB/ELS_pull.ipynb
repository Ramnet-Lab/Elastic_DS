{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f87e9ce5-fdc1-42f3-9300-327043740152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: elsds/bin/activate: No such file or directory\n",
      "Requirement already satisfied: elasticsearch in /opt/conda/lib/python3.12/site-packages (8.17.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /opt/conda/lib/python3.12/site-packages (from elasticsearch) (8.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /opt/conda/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e9f1c1-dee7-4de2-838d-20da5c5f85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Step 1: Connect to Elasticsearch\n",
    "# --------------------------------------------\n",
    "es = Elasticsearch(\n",
    "    [\"http://192.168.2.46:9200\"],\n",
    "    # Uncomment and update basic_auth if needed:\n",
    "    # basic_auth=(\"elastic\", \"password\"),\n",
    "    verify_certs=False,  # Adjust for production!\n",
    "    request_timeout=30,\n",
    "    max_retries=3,\n",
    "    retry_on_timeout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d28e36a-641a-44d6-ad43-6b501fda8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Step 2: Query across all indices using wildcard\n",
    "# --------------------------------------------\n",
    "index_pattern = \"*\"  # Pull data from all indices\n",
    "query_body = {\n",
    "    \"query\": {\"match_all\": {}},\n",
    "    \"sort\": [{\"@timestamp\": {\"order\": \"desc\"}}],\n",
    "    \"size\": 1000\n",
    "}\n",
    "scroll_duration = \"2m\"  # Duration for which the scroll context is maintained\n",
    "\n",
    "try:\n",
    "    page = es.search(index=index_pattern, body=query_body, scroll=scroll_duration)\n",
    "except Exception as e:\n",
    "    print(f\"Error during search: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "scroll_id = page.get('_scroll_id')\n",
    "hits = page['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a2b051-09c4-49f8-aa6e-f92a31e3b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Step 3: Collect all documents using the scroll API\n",
    "# --------------------------------------------\n",
    "documents = []\n",
    "documents.extend(hits)\n",
    "\n",
    "while True:\n",
    "    page = es.scroll(scroll_id=scroll_id, scroll=scroll_duration)\n",
    "    hits = page['hits']['hits']\n",
    "    if not hits:\n",
    "        break\n",
    "    documents.extend(hits)\n",
    "    scroll_id = page.get('_scroll_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc7deb43-62c8-4ee8-933b-a26fffb9a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Step 4: Build a DataFrame from the documents\n",
    "# --------------------------------------------\n",
    "if documents:\n",
    "    data = []\n",
    "    for doc in documents:\n",
    "        row = {}\n",
    "        row['_index'] = doc.get('_index', '')\n",
    "        source = doc.get('_source', {})\n",
    "        row.update(source)\n",
    "        data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    print(\"No documents found.\")\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9810394-90ca-4b60-8081-5f0117bfc674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Step 5: Define a function to parse JSON-like strings\n",
    "# --------------------------------------------\n",
    "def parse_json_value(val):\n",
    "    \"\"\"\n",
    "    Convert a JSON-like string (often with single quotes) into a dictionary.\n",
    "    If not a string or parsing fails, return the original value.\n",
    "    \"\"\"\n",
    "    if isinstance(val, str):\n",
    "        val = val.strip()\n",
    "        if (val.startswith(\"{\") and val.endswith(\"}\")) or (val.startswith(\"[\") and val.endswith(\"]\")):\n",
    "            try:\n",
    "                return ast.literal_eval(val)\n",
    "            except Exception:\n",
    "                return val  # Return the original string if parsing fails\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1feb59b-4bce-4510-b0ee-ced66d9a5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Step 6: Parse and flatten JSON columns\n",
    "# --------------------------------------------\n",
    "json_columns = ['agent', 'ecs', 'host', 'input', 'log']\n",
    "\n",
    "for col in json_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(parse_json_value)\n",
    "        parsed = df[col].apply(lambda x: x if isinstance(x, (dict, list)) else {})\n",
    "        # If the column contains only dictionaries, flatten it.\n",
    "        if parsed.apply(lambda x: isinstance(x, dict)).all():\n",
    "            expanded = pd.json_normalize(parsed)\n",
    "            expanded.columns = [f\"{col}.{subcol}\" for subcol in expanded.columns]\n",
    "            df = pd.concat([df.drop(columns=[col]), expanded], axis=1)\n",
    "        else:\n",
    "            # Leave the column as is; later, lists will be converted to strings for normalization.\n",
    "            df[col] = parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a219b9f1-dc9d-4fdf-a824-80e6d3c769da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# (Optional) Convert @timestamp to a datetime object\n",
    "# --------------------------------------------\n",
    "if '@timestamp' in df.columns:\n",
    "    df['@timestamp'] = pd.to_datetime(df['@timestamp'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b67882a4-5e8c-47d5-b1bf-80857fd7fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data exported to output.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# Step 7: Write the Actual (Flattened) Data to CSV\n",
    "# --------------------------------------------\n",
    "actual_csv = \"output.csv\"\n",
    "df.to_csv(actual_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"Actual data exported to {actual_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdb98237-d1f2-44be-b197-c1888702449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###STOP HERE IF NO NORMALIZED DATA NEEDED###\n",
    "###SEE ELS_norm IPYNB FOR DATA NORMALIZATION PIPELINE###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e467570-7bea-4bc8-a7a5-4545befdad59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
